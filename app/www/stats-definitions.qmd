---
title: ''
format:
  html:
    self-contained: false
    css: cc-style-bs4.css
---

![](codeclan-logo-blue.png){width=200 fig-align='left' fig-alt='CodeClan logo'}

:::{.callout-tip collapse=true icon=false}
## P value
When a change in what we do is followed by some change, it is tempting to believe that the change happened as a response to the change we implemented. For example, if after updating our website we receive a higher than usual income from sales, we might ascribe this increase to the new website.

Week to week, income will usually be fairly typical, but not exactly the same.
The exact income will swing higher and lower around some expected number
It is even possible for these wobbles to be quite extreme, just from sheer randomness.

The value in this box gives a way to assess how unusual the income is actually likely to be.
The more extreme the swing the more unusual the result will be, and the lower this number will become.
This number gives us a more objective idea of just how unusual a given sample is.

The box will turn green whenever the value is considered "meaningful".
:::

:::{.callout-tip collapse=true icon=false}
## Confidence interval

Even if we believe the difference in income truly is because of our website intervention, there will still be some fluctuation around the __new__ modified average.
If we took the average every week, they would be slightly different.
While we can compute the average for each week, the __true, underlying__ average will always be an unknown.
We can, however, construct a margin around each week's average that will give a sense of the true average.
The number shown here allows us to have some confidence that 95% of the margins we construct will cover the true, underlying average.

- The box is colour coded
    - __gold:__ the expected value is covered by the error bars.
    - __red:__ the observed value is below the expected value, and the expected value is not within the error bars.
    - __green:__ the observed value is higher than expected and the expected value is not covered by the error bars.
:::


:::{.callout-tip collapse=true icon=false}
## Density function

![Probability density curve](pdf.png){width=200 fig-align='left' fig-alt='Bell curve with threshhold at left tail'}

It is useful to have a threshold for which we deem an outcome to be meaningful.
The __probability density__ curve tells us the probability of getting a particular value from a distribution.
The curve is highest at the centre (i.e. at 0) because this is the most likely value, and values further away become decreasingly likely.
The most likely value is 0 because it represents the difference from the average, and there is a higher probability of being close to that average.

There is a convention in many statistical applications to use a value of 0.05 for the threshold, but We can choose any value we wish.
The higher the value we set, the easier it becomes to claim a meaningful difference.
That is, a value of 0.1 is more likely than 0.05.
However, if we set the value too high, we increase the risk of wrongfully declaring the difference fro the average as meaningful.

This curve is also useful for computing the probability of obtaining a value within a given range: perhaps between 0.05 and 0.1.
:::

:::{.callout-tip collapse=true icon=false}
## Cumulative distribution function

![Probability density curve](cdf.png){width=200 fig-align='left' fig-alt='S-shaped curve with threshhold at left tail'}
The cumulative distribution curve is related to the density curve.
In the density curve all possibilities are contained under the curve, such that the area adds up to one.
The cumulative distribution instead adds up all the possibilities and plot them on a line.
A given point on the line gives the probability of obtaining any value less than the chosen point
:::
