---
title: 'Stats definitions'
format:
  html:
    self-contained: true
    include-before-body: cc-data-banner.html
    css: cc-style-bs4.css
---

<!-- ![](codeclan-logo-blue.png){width=200 fig-align='left' fig-alt='CodeClan logo'} -->

:::{.callout-tip collapse=true icon=false}
## P value
When a change in what we do is followed by some change, it is tempting to believe that the change happened as a response to the change we implemented. For example, if after updating our website we receive a higher than usual income from sales, we might ascribe this increase to the new website.

Week to week, income will usually be fairly typical, but not exactly the same.
The exact income will swing higher and lower around some expected number
It is even possible for these wobbles to be quite extreme, just from sheer randomness.

The value in this box gives a way to assess how unusual the income is actually likely to be.
The more extreme the swing the more unusual the result will be, and the lower this number will become.
This number gives us a more objective idea of just how unusual a given sample is.

The box will turn green whenever the value is considered "meaningful".
It should also be noted that even the tiniest difference could be shown as meaningful if the sample size is large enough.

:::{.callout-warning collapse=true}
## For the pendant
Be aware that this is for illustration of concepts only.
In reality, while the historic mean is a known quantity, it is also an estimation of what the _real mean_ for the given situation might be - i.e. if history itself could be repeated an infinite number of times.
In particular, the expeted value would be more correctly shown with some indication of its own inherent uncertainty.
This might be shown through its own confidence interval (or its __standard error__).
:::
:::

:::{.callout-tip collapse=true icon=false}
## Confidence interval

Even if we believe the difference in income truly is because of our website intervention, there will still be some fluctuation around the __new__ modified average.
If we took the average every week, they would be slightly different.
While we can compute the average for each week, the __true, underlying__ average will always be an unknown.
We can, however, construct a margin around each week's average that will give a sense of the true average.
The number shown here allows us to have some confidence that 95% of the margins we construct will cover the true, underlying average.

- The box is colour coded
    - __gold:__ the expected value is covered by the error bars.
    - __red:__ the observed value is below the expected value, and the expected value is not within the error bars.
    - __green:__ the observed value is higher than expected and the expected value is not covered by the error bars.

:::{.callout-warning collapse=true}
## For the pendant
Although it is possible to show confidence intervals immediately this app initializes, be aware that it starts with  sample of size 2.
Confidence intervals for a sample of that size are pointless at best and misleading if used with nefarious intent!

![Trump's doctored hurricane map. Shows confidence interval for path of hurricane, plus... ??](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi0.wp.com%2Ftruepundit.com%2Fwp-content%2Fuploads%2F2019%2F09%2Fh2-trump-black-marker-sharpie-map-hurricane-dorian-alabama.jpg%3Ffit%3D960%252C540%26ssl%3D1&f=1&nofb=1){width=30%}
:::
:::

:::{.callout-tip collapse=true icon=false}
## Cumulative distribution function

![Cumulative probability curve](distr_plot_cdf.png){width=200 fig-align='left' fig-alt='S-shaped curve with threshhold at left tail'}

The cumulative distribution curve is related to the density curve.
In the density curve all possibilities are contained under the curve, such that the area adds up to one.
The cumulative distribution instead adds up all the possibilities and plot them on a line.
A given point on the line gives the probability of obtaining any value less than the chosen point
:::

:::{.callout-tip collapse=true icon=false}
## Density function

![Probability density curve](distr_plot_pdf.png){width=200 fig-align='left' fig-alt='Bell curve with threshhold at left tail'}

It is useful to have a threshold for which we deem an outcome to be meaningful.
The __probability density__ curve tells us the probability of getting a particular value from a distribution.
The curve is highest at the centre (i.e. at 0) because this is the most likely value, and values further away become decreasingly likely.
The most likely value is 0 because it represents the difference from the average, and there is a higher probability of being close to that average.

There is a convention in many statistical applications to use a value of 0.05 for the threshold, but We can choose any value we wish.
The higher the value we set, the easier it becomes to claim a meaningful difference.
That is, a value of 0.1 is more likely than 0.05.
However, if we set the value too high, we increase the risk of wrongfully declaring the difference fro the average as meaningful.

This curve is also useful for computing the probability of obtaining a value within a given range: perhaps between 0.05 and 0.1.
:::

