---
title: 'Identifying Uncertainty<span style="color: #e6c372;">_</span>'
format: 
  html:
    toc: true
    mainfont: Gilroy
    fontsize: 1.4rem
    link-external-newwindow: true
    canononical: true
css: style.css
---

```{=html}
<style>
  h1.title { font-size: 2.8rem; }
</style>
```
::: {.callout-important icon="false" collapse="true"}
## Notes to instructor

This session is intended to run as a facilitated discussion aimed at raising participant's ability to reason about uncertainty.

As much as possible it should be run with instructors taking more of a supporting role, rather than actively engaging throughout.
It might be helpful for the first round for each group to have an instructor sit close by to help them understand the process.
For subsequent round, instructors should hopefully be able to float between groups, and confer amongst themselves; perhaps to discuss timings.

The groups will be given a scenario to help consider the sources of uncertainty and how it affects decision making.
They then have to report back to the other group(s) with a short summary of their ideas.
Tell them that their short summary should include links to their own work.
For example given how they discussed the uncertainty in their scenario, how could those insights be transferred to the uncertainty data / situations in their working day.

::: columns
::: column
![](images/d1-s2--session-outline.png)
:::

::: column
Groups need to be provided with materials for taking notes.
Pens, post-it notes, A3 paper or access to a whiteboard.

Brief groups to nominate a scribe and someone to report back.

There is a cycle to the session, the scribe / reporters can (should?) change in each cycle.
:::
:::
:::

## Learning outcomes

-   Develop awareness of different sources of uncertainty.
-   Realise that uncertainty is normal and cannot be removed or ignored.
-   Realise that it is possible to develop strategies for dealing with uncertainty that can make decisions more robust.
-   Awareness that own (un)concious biases affect interpretation of uncertainty.

## Intro

Trying to make data-based decisions can often feel like a no-win situation.
There always seems to be too many "what ifs?", that can make it feel like there is no good choice.

## Questions

::: {.callout-important icon="false" collapse="true"}
## Suggested timings

The timings below suggest where flexibility lies in manipulating the session timings.
Long breaks between question are good for handling overflow, and for keeping participants refreshed.

This also means shorter discussions for each question.
**Keep an eye on group progress**: ensure they are covering ground, and not wasting too much time on details.
The focus of the session should be on bringing high level concepts out in good time.

::: columns
::: {.column width="40%" style="background-color: #00e2"}
#### Flexible timings

-   20-25 mins for discussion
-   5-10 mins to report back to class
-   5-10 mins for open forum
-   5-15 min breaks after each round
:::

::: {.column width="40%" height="100%" style="background-color: #e002"}
#### Rigid timings

-   20 minutes for discussion
-   5 minutes to report back to class
-   5 minutes for open forum
-   15 min break after each round
:::

The timings on the right allow for up to \~15 minutes for post-session wrap up by instructor
:::

If you decide to do only 3 rounds, that will free up an extra 45 minutes, which could be distributed over the question and give extra time for summarizing at the end.
:::

```{r}
#| eval: false
#| include: false

# 3hrs = 180mins
# 3 * 15 min breaks = 45mins
180 - 45
# 4 sessions
135 / 4

# 20 min discussion
#  5 min to report
#  5 min open forum
# 15 min break after each of first 3 session
# Leaves ~ 15 min at end
```

The following sections outline topics for 4 iterations of the learning cycle.
It is important to keep a close eye on timings (see box below).
How many, and which, questions to use should be down to instructors discretion

### Q1: What is uncertainty?

Aims:

:   Understand what we actually mean by "uncertainty".
    Realise where uncertainty arises.
    And how different sources of uncertainty might allow / call for different strategies.

::: {.callout-important icon="false" collapse="true"}
-   Sometimes uncertainty is just a normal part of a process.
    -   This is often just inherent random noise.
    -   Other times there may be a pattern associated
    -   Ask participants if they can think of examples of both types.
-   Sometimes the uncertainty originates with the person trying to work with the data.
    -   E.g. a lack of knowledge or experience.
    -   Should be easy to deal with by working with a diverse team.
        -   Just asking for help might be enough.
    -   Could it be an opportunity?
        -   Personal development / staff training?
    -   **This will lead into the next question about biases**
-   These are examples of uncertinty we can identify.
    -   But there may also be uncertainty about what we know
    -   I.e. not knowing what we don't know
        -   How can we prepare for things we don't even suspect?
:::

### Q2: Biases

Aims:

:   Recognize that sometimes it is difficult to update our preexisting world view.
    We all have preconcieved notions, i.e., this is normal, but ot can become a problem if they blind us to patterns in out data.
    Discuss how different types of bias affect our judgments.
    How can we go about mitigating our biases.

::: {.callout-important icon="false" collapse="true"}
## Consider steering group is different directions

The are examples of two different areas where bias can arise.
It might be interesting to have different groups explore both of these (or others).

It may be necessary to drop a hint about the importance of context framing when trying to confront biases.

Many of these overlap

-   **Cognitive biases**
    -   Confirmation bias.
        -   When you believe something to be true, then see it happen, your beliefs are confirmed; but maybe it was just coincidence.
    -   Pet theories
        -   Perhaps you're so convinced a certain decision or course of action is for the best, you can't / won't consider alternatives.
-   **Data biases**
    -   Selection bias
        -   If ads target a particular demographic, it might be easy to assume that everyone is similar to the respondents, when reaaly they could be a very distinct subset.
    -   Survivor effects
        -   How do customers ustomers that don't churn (survivors) affect perceptions
    -   Attrition bias (kind of)
        -   Who are the customers that churn?
        -   Is there a systematic pattern that makes certain types of people more likely to churn?
:::

### Q3: Managing our uncertainty

Aims:

:   Identify the steps that can help reduce anxiety caused by uncertainty, and that might suggest strategies of minimizing disruption.
    Discuss how we might begin to quantify either the uncertainty itself, or its consequences on decision making (this will help set up tomorrows lab session).

Appropriate management of uncertainty will depend on both where the uncertainty originates, and how we percieve and interact with the causes (i.e. the two prevous topics).

::: {.callout-important icon="false" collapse="true"}
## Try and work towards a framework

*Note:* this flowchart below is not evidence based - I made it up.
It is just a idea that seems reasonable as a starting point for discussion or maybe building a more targeted strategy.

![](images/manage-uncertainy-flowchart.png)

1.  Identify the problem or situation of interest.\
2.  Formulate a clear, unambiguous question / problem statement.\
3.  Collate and distill evidence on the sources of uncertainty.\
4.  Quantify the range of outcomes: weight on the outcomes according to how likely they are based on the evidence.\
5.  Formulate one or more courses of action.

How might you quantify the uncertainty?
i.e. how large an effect is the uncertainty likely to have on expectations?
:::

## Q4: How can we become comfortable with uncertainty?

**Aim:** To try and set expectation that, since incertainty exists, and we cannot completely remove it, we need to learn to *embrace* it.

::: {.callout-important icon="false" collapse="true"}
## Since we can't beat it, let's plan for it

-   What if everyone else (i.e. competitiors) manages uncertainty better that you?
-   Is there any danger of overcompensating?
    -   i.e. trying to plan for too many possibilities?
-   **This would be a good time to hint at some kind of modeling approack**
:::

::: {.callout-important icon="false" collapse="true"}
## Good thing; bad thing

-   What advantages might come from planning for different circumstances?
-   What disadvanteges might associated with planning for uncertainty?
:::
