---
title: "Uncertainty lab"
format:
  html:
    toc: true
    self-contained: true
---

## OUTLINE

### Sampling

- Hit `New sample` repeatedly
- Notice that each time the `observed` value changes
    - sometimes higher than expected, sometimes lower
- Increase the `Average value` input to 120
    - Hit `New sample` a few more times
    - Notice now that the value still changes every time, but is below the expected value less often
- Return `Average value` to 100
- Increase `Sample size` to 100
    - Hit `New sample` a few more times
    - Notice notice that while the observed value still fluctuates both above and below the expected line, it is far closer to the expected line
- Ensure `Average value` is set to 100
- Return `Sample size` to 5
- Check the `Show points` box
- Repeat the above
- Examine the effect of `spread`
    - If sales (or whatever) are fairly homogeneous, spread is small averages are more consistent
    - If `spread` is large, averages are swingier, and so a larger sample is more important

### P-value

- How do we know if the difference is meaningful?
- Always a chance it is not
- Some samples will be less consistent with meanigfulness than others
- P value gives a way to judge
- Insert questions to exampne how parameters `n` and `spread` affect `P`

### Confidence interval

- However a p value has several shortcomings
- A confidence interval can be used to temper soe of the excitment of reaching significance
    - But is subject to kind of the same shortcomings

### Distribution function

- To help give context to p vaule
- who says a p value is significant
- Illustrate CDF
    - $P = 50 / 50$ for whether an observed value is higher or lower than expected (when x axis = 0)
    - The CDF is the sum of all probs under a given value.
        - So the further the observed gets in the negative direction the closer P gets to 0
        - and the further the observed gets in the positive direction the closer P gets to 1
            - When P is close to 1 we are interested in the probability of being even higher than the given value.
- Illustrate PDF
    - First just gives a clearer image of how the tails are equally sized at each end of the distribution
    - Secondly, we can see how even the shape of the curve is different for very small `n` 
    - Thirdly, how the significance thresholds depend on `n` - i.e. it is harder to cross the threshold when `n` is small
    
### Accidental extra

- Opening the `Data summary` section, we can see how a small sample leads to an empirical distribution that is very different from the theoretical distribution.

****************************

## Scenario

Consider a situation where a business has an average weekly profit of exactly £100.
This figure is the average over the entire history of the business, and is know to be exactly correct.

The boss of this business wants to increase its average weekly profit, so decides to change its website to more effectively target a different subset of its customers.

In the first week following changes to the website they find they made a profit of £109.66.
Higher indeed than the expected average of £100.

<!-- ![Profit for the week following website changes](improved-sales.png){#fig-improved-profit fig-align='left' width=30% alt='The profit observed in the week following improvements to the website was £109.66'} -->

The CEO congratulates the team, and declares their new website a success.

Was the CEO right to do so?


:::{.callout-tip icon=false}
## Task -- 10mins

With the rest of your group discuss what more information you would like to know before agreeing or disagreeing with the boss.

Create a list of as many important questions you can think of, that you would like answered.

:::{.callout collapse='true' appearance='minimal'}
## Suggestions

Some possible questions we would like to have answered:

- How big would we like the increase to be before declaring it a success?
- How big was the increase in profit?
    - A particularly large deviation from expected may be less likely to be within normal range of fluctuations.
- How many sales were made?
    - A single large (or small) sale could have an over-sized influence on the average: consider the extreme case where only one sale of £1000 was made.
- How similar in size were the individual sales?
    - Did all the sales occur around the same value, or were they spread out across a wide range.
    - How typical such a range of values is would be an important consideration.
- How likely is it that we just got lucky this week?
    - Again consider a single rare, but high value, sale.

:::

:::

We are going to explore how different possible answers to those questions might affect how we come to a decision.

## Average expectation

![Sample average (observed) vs expected average](01--data-literacy-lab--sample-size.png){#fig-exp-vs-sample fig-align='left' width=30% alt='Plot showing a horizontal line labelled "Expected" at y = 100 and a point slightly above the expected line indicating the average observed from a sample.'}

@fig-exp-vs-sample above shows a horizontal gold line at £100.
This indicates the all-time historic average for our company.
For the purposes of this exercise, we shall consider this a our unambiguous "truth" of what our business has made in an average week.
It is therefore not a statistic, since statistics are values that are used to __estimate__ "true" parameters.

Looking at  we see that the recent sample yielded an average profit higher than the historic average.



:::{.callout-tip icon=false}
### __Questions__

1. How much would you trust that this increased profit is likely to continue in future weeks?
1. What factors can you identify that might support your answer for question 1?
    i. If you would be enthusiastic that this is a strong result to take to the line manager, create a list of reasons that justify your belief.
    i. If you are less than enthusiastic create a list of reasons, along with ideas that would increase your willingness to go to the boss.
    i. If you are not sure, create both of the above lists!

:::

Now that you have created a list follow this [link][app-link].
The plot on the left is the same as that in @fig-exp-vs-sample, but with a different "observed" value.
We can simulate what the observed value might be like in future weeks by pressing the ![new sample](new-sample-button.png){width=20%} button.
Press it several times, and after each press notice that the observed value changes - possibly by quite a lot!
There are several controls in the left sidebar that we can experiment with to help understand which situations might lead to more reliable results.
There are a lot of controls, so lets explore them one at a time.

## Sample size

The first control on the left is labeled "sample size", and is currently set at 2.
This means that our observed average is based on only two customers.
If our data are based on inly 2 customers how likely is it that they reprsent our "average customer"?


**************************************


<!-- Image links -->


[app-link]:https://cc-stats.shinyapps.io/uncertainty




*********************



## Links



